{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Understanding Autoencoders\n","\n","**Introduction**\n","\n","What is an autoencoder?\n","*   A special type of unsupervised (no labels needed) feedforward neural network\n","*   Captures the key aspects of the input data to provide a compressed version\n","\n","Autoencoders are composed of two connected feedforward neural networks.\n","\n","\n","*   The **encoder** compresses the input data to remove noise and generates a latent space, where items that are similar to one another are close to each other.\n","*   The **decoder** uses the compressed data representation to reconstruct the original input data. This reconstruction can then be compared to the original input using a loss function.\n","\n","**Types of Autoencoders**\n","\n","There are many types of autoencoders that have been developed for a variety of applications.\n","\n","*   Undercomplete Autoencoder\n","*   Sparse Autoencoder\n","*   Contractive Autoencoder\n","*   Denoising Autoencoder\n","*   Convolutional Autoencoder\n","*   Variational Autoencoder\n","\n","![alttext](denoising_models/autoencoder.png)"]},{"cell_type":"markdown","metadata":{"id":"BvAMneiSxaDk"},"source":["\n","# Denoising Autoencoders\n","\n","In this notebook, we'll focus on denoising autoencoders. When the size of the latent space is equal to or greater than the size of the input, an autoencoder might learn the identity function during training. When this happens, the output will equal the input, meaning the autoencoder is not contributing anything.\n","\n","**Simplified Theory**\n","\n","Denoising autoencoders address this problem by intentionally corrupting the data. When calculating the loss function, we compare the output with the original input (not the corrupted input), eliminating the risk that the model learns the identity function. As a result, we train a model that takes in corrupted data and attempts to reconstruct uncorrupted data.\n","\n","![alttext](denoising_models/denoise.png)\n","\n","**Hands-On Example**\n","\n","Let's start by building a denoising autoencoder.\n","\n","We start with an input layer that takes in batches of images with size 28 pixels by 28 pixels. The input layer is then followed by a series of Convolutional and Max Pool layers that compress the images and extract features. Together, these initial layers will be our encoder."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":140,"status":"ok","timestamp":1715305302488,"user":{"displayName":"Milo Chang","userId":"09434874569141687542"},"user_tz":240},"id":"ptgN9QozXDX8"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            # Layer 1: Convolutional + Max Pooling\n","            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # Output: (16, 28, 28)\n","            nn.ReLU(True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: (16, 14, 14)\n","            # Layer 2: Convolutional + Max Pooling\n","            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),  # Output: (32, 14, 14)\n","            nn.ReLU(True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: (32, 7, 7)\n","            # Layer 3: Convolutional + Max Pooling\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # Output: (64, 7, 7)\n","            nn.MaxPool2d(kernel_size=2, stride=2)  # Output: (64, 3, 3)\n","        )\n","\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","      for m in self.modules():\n","        if isinstance(m, nn.Conv2d):\n","          nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n","          if m.bias is not None:\n","            nn.init.constant_(m.bias, 0)"]},{"cell_type":"markdown","metadata":{"id":"1L6LCJjGX8eW"},"source":["Next we'll build the decoder. The architecture of the decoder is basically a reverse of the encoder, allowing us to obtain an image that matches the original dimensions."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715305302663,"user":{"displayName":"Milo Chang","userId":"09434874569141687542"},"user_tz":240},"id":"F5LiefTDYpS2"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","        self.decoder = nn.Sequential(\n","            # Layer 1: Transposed Convolution\n","            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2),  # Output: (32, 7, 7)\n","            nn.ReLU(True),\n","            # Layer 2: Transposed Convolution\n","            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),  # Output: (16, 14, 14)\n","            nn.ReLU(True),\n","            # Layer 3: Transposed Convolution\n","            nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=1),  # Output: (1, 28, 28)\n","            nn.Sigmoid(),\n","        )\n","\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.decoder(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","      for m in self.modules():\n","        if isinstance(m, nn.ConvTranspose2d):\n","          nn.init.xavier_normal_(m.weight)\n","          if m.bias is not None:\n","            nn.init.constant_(m.bias, 0)"]},{"cell_type":"markdown","metadata":{"id":"hjSz5FDZm0aE"},"source":["Let's piece together our encoder and decoder to define our denoising autoencoder."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715305302663,"user":{"displayName":"Milo Chang","userId":"09434874569141687542"},"user_tz":240},"id":"TGePFJ7tm8z6"},"outputs":[],"source":["class DenoisingAutoencoder(nn.Module):\n","    def __init__(self):\n","        super(DenoisingAutoencoder, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return decoded"]},{"cell_type":"markdown","metadata":{"id":"XuqbAvonbJG7"},"source":["Next, we'll need to prepare some training data. Let's intentionally corrupt some image data from the MNIST dataset to give us input data for our denoising autoencoder. We'll start by defining a function that adds noise to an image."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715305302663,"user":{"displayName":"Milo Chang","userId":"09434874569141687542"},"user_tz":240},"id":"KDdmCu07bjad"},"outputs":[],"source":["# Adding Guassian Noise to an image\n","def gaussian_noise(image):\n","    c, h, w = image.size()  # Assuming image is (channels, height, width) and grayscale\n","    mean = 0\n","    var = 0.1\n","    sigma = var ** 0.5\n","    gaussian = torch.normal(mean, sigma, size=(h, w))\n","    noisy = image + gaussian\n","    return torch.clamp(noisy, min=0, max=1)"]},{"cell_type":"markdown","metadata":{"id":"d5HbUsneb0oz"},"source":["Let's use our noise function to corrupt the MNIST dataset. We should also make sure to remember what the uncorrupted images looked like so we can use them in our training later."]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25440,"status":"ok","timestamp":1715305328101,"user":{"displayName":"Milo Chang","userId":"09434874569141687542"},"user_tz":240},"id":"xP-IJcHmb40S","outputId":"d6fe0ca1-7add-4bdd-cb06-db3906db1af2"},"outputs":[],"source":["from torchvision import datasets, transforms\n","from matplotlib import pyplot as plt\n","from torch import tensor\n","import numpy as np\n","\n","train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n","\n","# corrupted MNIST images for training\n","mnist_corrupt_train = [(gaussian_noise(image), image) for image, _ in train_dataset]\n","\n","test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n","\n","# corrupted MNIST images for testing\n","mnist_corrupt_test = [(gaussian_noise(image), image) for image, _ in test_dataset]"]},{"cell_type":"markdown","metadata":{"id":"0Bdirp-Xzx2B"},"source":["Let's plot some of the images in our training set to see what we're working with."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1944,"status":"ok","timestamp":1715305330042,"user":{"displayName":"Milo Chang","userId":"09434874569141687542"},"user_tz":240},"id":"qDgCIDuJ-MPW","outputId":"001be28d-1802-47c8-945d-685693835cb5"},"outputs":[],"source":["for i in range(9):\n","  # Create a figure with subplots\n","  fig, axes = plt.subplots(1, 2, figsize=(10, 4))  # 1 row, 2 columns\n","  corrupted, original = mnist_corrupt_train[i]\n","\n","  # Plot each image\n","  axes[0].imshow(original.squeeze(), cmap='gray')\n","  axes[0].set_title('Original Image')\n","  axes[0].axis('off')  # Hide axes\n","\n","  axes[1].imshow(corrupted.squeeze(), cmap='gray')\n","  axes[1].set_title('Corrupted Image')\n","  axes[1].axis('off')  # Hide axes\n","\n","  # Display the plot\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"6qwEHG84ZASa"},"source":["In order to start training our denoising autoencoder, we need to define our loss function. We'll define our loss as the mean squared error between the output of the decoder and the original, uncorrupted image."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715305330042,"user":{"displayName":"Milo Chang","userId":"09434874569141687542"},"user_tz":240},"id":"Jwf0SYYwatlS"},"outputs":[],"source":["def denoise_loss(output, original):\n","  mse_loss = nn.MSELoss()\n","  return mse_loss(output, original)"]},{"cell_type":"markdown","metadata":{"id":"8B5TrJBlhcQJ"},"source":["Now that we corrupted our MNIST images, we can train our denoising autoencoder to reconstruct the original, uncorrupted images.  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QZzAFqG6iYEP","outputId":"aa345c33-c8ee-49c1-e486-b6e112230ab0"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","\n","def minibatch_loss(model, input_imgs, target_imgs):\n","    reconstructed_imgs = model(input_imgs)\n","    loss = denoise_loss(reconstructed_imgs, target_imgs)\n","    return loss\n","\n","def minibatch_gd(model, num_epochs, train_set, test_set, lr=0.01):\n","  train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n","  test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n","\n","  for _ in tqdm(range(num_epochs)):\n","    model.train()\n","    for corrupt_imgs, original_imgs in train_loader:\n","      loss = minibatch_loss(model, corrupt_imgs, original_imgs)\n","      loss.backward()\n","      for param in model.parameters():\n","        with torch.no_grad():\n","          param -= lr*param.grad\n","          param.grad = None\n","\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","      for corrupt_imgs, original_imgs in test_loader:\n","          loss = minibatch_loss(model, corrupt_imgs, original_imgs)\n","          total_loss += loss.item()\n","\n","if __name__ == \"__main__\":\n","    train_set = mnist_corrupt_train\n","    test_set = mnist_corrupt_test\n","    num_epochs = 100\n","    model = DenoisingAutoencoder()\n","    minibatch_gd(model, num_epochs, train_set, test_set)\n","    torch.save(model.state_dict(), \"mnistmodel100.pt\")"]},{"cell_type":"markdown","metadata":{"id":"FW4zbiIQPVvM"},"source":["Now that our model is trained, let's see how it performs on some of our test data!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2153,"status":"ok","timestamp":1715308841986,"user":{"displayName":"Milo Chang","userId":"09434874569141687542"},"user_tz":240},"id":"i0EYKFg11fwH","outputId":"a848b4d0-5b75-4bbc-8f4c-c4ad793f12be"},"outputs":[],"source":["train_set = mnist_corrupt_train\n","test_set = mnist_corrupt_test\n","model = DenoisingAutoencoder()\n","# Pre-trained models are available for 1, 2, 10, 25, 50, 100, and 400 epochs\n","model.load_state_dict(torch.load('denoising_models/mnistmodel400.pt', map_location=torch.device('cpu')))\n","model.eval()\n","\n","sample_indices = [100, 502, 800, 900]\n","\n","for i in range(len(sample_indices)):\n","  input_image, original_image = test_set[sample_indices[i]]\n","  output_image = None\n","\n","  with torch.no_grad():\n","      output_image = model(input_image)\n","\n","  # Create a figure with subplots\n","  fig, axes = plt.subplots(1, 3, figsize=(10, 4))  # 1 row, 3 columns\n","\n","  # Plot each image\n","  axes[0].imshow(input_image.squeeze(), cmap='gray')\n","  axes[0].set_title('Corrupted Image')\n","  axes[0].axis('off')  # Hide axes\n","\n","  axes[1].imshow(output_image.squeeze(), cmap='gray')\n","  axes[1].set_title('Denoised Output')\n","  axes[1].axis('off')  # Hide axes\n","\n","  axes[2].imshow(original_image.squeeze(), cmap='gray')\n","  axes[2].set_title('Original Image')\n","  axes[2].axis('off')  # Hide axes\n","\n","  # Display the plot\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"yScMqz0RPdEo"},"source":["As we can see, our denoising autoencoder does a pretty good job of taking our corrupted images and generating something that resembles the original image. The results we see come from 50 epoches of training. The more epoches we complete, the closer  the denoised output will be to the original image!"]},{"cell_type":"markdown","metadata":{"id":"qhEiQrdeXtoJ"},"source":["**Real World Applications**\n","\n","As we've seen, denoising autoencoders are great at reducing the noise in images and extracting the important aspects of the image. This is why they're used for applications like:\n","\n","\n","*   Optical Character Recognition (OCR) - converting an image of text into machine-readable text\n","*   Handwritten Text Recognition - converting handwritten text into machine-readable text\n","*   Image Recovery - restoring corrupted images to recover their features\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"F0bEj_O8xiyt"},"source":["# Credits\n","* [Autoencoders (2021)](https://arxiv.org/pdf/2003.05991)\n","* [Introduction to Autoencoders: From The Basics to Advanced Applications in PyTorch](https://www.datacamp.com/tutorial/introduction-to-autoencoders)\n","* [Denoising Autoencoders Explained](https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2)\n","* [Denoising AutoEncoders Can Reduce Noise in Images](https://medium.com/game-of-bits/denoising-autoencoders-can-reduce-noise-in-images-5b74753eaf97)\n","* [How to Develop a CNN for MNIST Handwritten Digit Classification](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
